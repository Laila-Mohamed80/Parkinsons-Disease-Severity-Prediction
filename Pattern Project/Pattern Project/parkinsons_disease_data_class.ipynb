{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68c7b519-a66c-4d7b-a584-8b21a1fd7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import pointbiserialr\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb38812c-8a23-4c74-891f-7db3b6ea5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourPreProcessing(df, columnName):\n",
    "    for i in range(len(df)):\n",
    "        oldValue = df.loc[i, columnName]\n",
    "        if ':' in oldValue:\n",
    "            hour,minute = oldValue.split(':')\n",
    "            hour=float(hour)*60\n",
    "            minute = float(minute)\n",
    "            newValue = hour+minute\n",
    "            newValue /=60\n",
    "        else:\n",
    "            newValue = float(oldValue)\n",
    "        df.loc[i, columnName] = newValue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03011120-0b21-41bc-9514-8b13889c4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnDropper(df, columnName):\n",
    "    df.drop(columnName, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52fb9010-a790-4697-80b3-f35f3ecc96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColumnSeparator(df, columnName):\n",
    "    for i in range(len(df)):\n",
    "        value = df.loc[i, columnName]\n",
    "        items = value.split(', ')\n",
    "        for item in items:\n",
    "            key, val = item.split(': ')\n",
    "            key=key.strip(\"{'\")\n",
    "            val=val.strip(\"'}\")\n",
    "            df.loc[i, key] = val\n",
    "    df.drop(columns=[columnName], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2225a278-bde3-4633-a777-c41b4f527875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumPreprocessing(data, df):\n",
    "    # Create a HealthyLifestyleScore and drop original components\n",
    "    df = df.copy()\n",
    "    print(df.columns)\n",
    "    df['HealthyLifestyleScore'] = (\n",
    "        df['DietQuality'] + df['SleepQuality'] + pd.to_numeric(df['WeeklyPhysicalActivity (hr)'])\n",
    "    ) / 3\n",
    "    df.drop(['WeeklyPhysicalActivity (hr)', 'DietQuality', 'SleepQuality'], axis=1, inplace=True)\n",
    "\n",
    "        #print(NumData)\n",
    "    results = []\n",
    "    for feature in df.columns:\n",
    "        correlation, p_value = pointbiserialr(data['Diagnosis'], df[feature])\n",
    "        results.append({\n",
    "            'Feature': feature, \n",
    "            'Correlation': correlation,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    top_10_significant = results_df.sort_values(by='p_value').head(10)\n",
    "    selected_columns = top_10_significant['Feature'].tolist()  \n",
    "    #print(NumData[selected_columns])\n",
    "    df =df[selected_columns]\n",
    "\n",
    "    train_mean = df.mean()\n",
    "    with open('meanClass.pkl', 'wb') as f:\n",
    "        pickle.dump(train_mean, f)\n",
    "\n",
    "    # Scale numeric data\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    df_scaled = pd.DataFrame(df_scaled) \n",
    "\n",
    "    # Save the scaler for future use\n",
    "    with open('scalerClass.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    return df_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ccba9ad-b5b3-4226-8ffc-9b9b7fbffbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encodingCategorical(data, df):\n",
    "    label_encoders = {}\n",
    "\n",
    "    # Ensure df is a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "\n",
    "    for column in df.columns:\n",
    "        le = LabelEncoder()\n",
    "\n",
    "        # Add 'Others' category to the unique values from training data\n",
    "        all_values = list(df[column].unique()) + ['Z']\n",
    "\n",
    "\n",
    "        # print(list(df['Depression'].unique()))\n",
    "        # Fit the encoder once with known values\n",
    "        le.fit(all_values)\n",
    "\n",
    "        # Apply encoding on the actual column from the original dataset\n",
    "        df.loc[:, column] = le.transform(data[column])\n",
    "\n",
    "        # Save the encoder for future use (e.g., test time)\n",
    "        label_encoders[column] = le\n",
    "\n",
    "    # Save all encoders to a file\n",
    "    with open('label_encodersClass.pkl', 'wb') as f:\n",
    "        pickle.dump(label_encoders, f)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8d5aca1-fa68-4d65-9a6a-00a96f0c93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CategoricalPreprocessing(data, df):\n",
    "    results = []\n",
    "    \n",
    "    for feature in df:\n",
    "    \n",
    "        crosstab = pd.crosstab(df[feature], data['Diagnosis'])\n",
    "        chi2, p, dof, expected = chi2_contingency(crosstab)\n",
    "        results.append({\n",
    "            'Feature': feature,\n",
    "            'Chi2_statistic': chi2,\n",
    "            'p_value': p\n",
    "        })\n",
    "    \n",
    "    chi2_df = pd.DataFrame(results)\n",
    "    \n",
    "    chi2_df_sorted = chi2_df.sort_values(by='p_value').head(10)\n",
    "    selected_columns =chi2_df_sorted['Feature'].tolist()  \n",
    "    df =df[selected_columns]\n",
    "    # print(df)\n",
    "    \n",
    "    train_mode = df.mode()\n",
    "    with open('modeClass.pkl', 'wb') as f:\n",
    "        pickle.dump(train_mode, f)\n",
    "\n",
    "    encoded_df = encodingCategorical(data, df)\n",
    "\n",
    "    # encoded_df['Disease Symptoms'] =  (encoded_df['Tremor'] + encoded_df['Bradykinesia'] + encoded_df['SleepDisorders'] + encoded_df['PosturalInstability']) / 4\n",
    "    # encoded_df['ChronicDiseasesScore'] = (encoded_df['Hypertension'] + encoded_df['Diabetes']) / 2\n",
    "    # #\n",
    "    # encoded_df.drop(['Tremor', 'Bradykinesia','SleepDisorders', 'PosturalInstability','Hypertension', 'Diabetes'], axis=1, inplace=True)\n",
    "    return encoded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad7ca0cf-303a-4669-a2a2-43dd084816e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessing():\n",
    "    data= pd.read_csv(\"parkinsons_disease_data_cls.csv\")\n",
    "    \n",
    "    # print(data.head())\n",
    "    # print(data.describe())\n",
    "    # print(data.shape)\n",
    "    # print(data.isnull().sum())\n",
    "\n",
    "    mode = data['EducationLevel'].mode()[0]\n",
    "    data['EducationLevel'] = data['EducationLevel'].fillna(mode)\n",
    "    # print(\"Duplicated values:\")\n",
    "    # print(data.duplicated().sum())\n",
    "\n",
    "    hourPreProcessing(data, 'WeeklyPhysicalActivity (hr)')\n",
    "    columnDropper(data, 'PatientID')\n",
    "    columnDropper(data, 'DoctorInCharge')\n",
    "    NumData = data.drop( columns=['Gender','Smoking','EducationLevel','Ethnicity','Symptoms','MedicalHistory','Diagnosis'])\n",
    "    target=data['Diagnosis']\n",
    "    finalNumDF=NumPreprocessing(data,NumData)\n",
    "    ColumnSeparator(data,'MedicalHistory')\n",
    "    ColumnSeparator(data,'Symptoms')\n",
    "    categorical_columns = ['Gender', 'Ethnicity', 'EducationLevel', 'Smoking',\n",
    "                       'FamilyHistoryParkinsons', 'TraumaticBrainInjury', 'Hypertension',\n",
    "                       'Diabetes', 'Depression', 'Stroke', 'Tremor', 'Rigidity',\n",
    "                       'Bradykinesia', 'PosturalInstability', 'SpeechProblems',\n",
    "                       'SleepDisorders', 'Constipation']\n",
    "    category_Data = data[categorical_columns]\n",
    "    # print(category_Data.columns)\n",
    "    # print(NumData.columns)\n",
    "    encoded_category_data = CategoricalPreprocessing(data, category_Data)\n",
    "    data=pd.concat([finalNumDF,encoded_category_data],axis=1)\n",
    "\n",
    "    # print(data.columns)\n",
    "    data['Diagnosis']=target\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83ef7960-6178-4d65-8f23-9c3fb49198fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(data):\n",
    "    y = data['Diagnosis']  \n",
    "    X = data.drop('Diagnosis', axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    svm_results = []\n",
    "    C_values = [0.1, 1, 10] \n",
    "    for C_val in C_values:\n",
    "        svm = SVC(C=C_val)\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        svm_results.append({\n",
    "            'C': C_val,\n",
    "            'accuracy': accuracy,\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "      \n",
    "    return svm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "faf41750-4149-4bce-a85c-4276a5009b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(data):\n",
    "    X = data.drop('Diagnosis', axis=1)\n",
    "\n",
    "    y = data['Diagnosis']  \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    dt_results = []\n",
    "    max_depth_values = [3, 5, 10]  \n",
    "    for max_depth_val in max_depth_values:\n",
    "        dt = DecisionTreeClassifier(max_depth=max_depth_val)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred = dt.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        dt_results.append({\n",
    "            'max_depth': max_depth_val,\n",
    "            'accuracy': accuracy,\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "    return dt_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46a30309-164d-4aec-802c-618214e53744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB(data):\n",
    "    X = data.drop('Diagnosis', axis=1)\n",
    "\n",
    "    y = data['Diagnosis']  \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    gb_results = []\n",
    "    learning_rate_values = [0.01, 0.1, 0.3]  # ثلاث قيم مختلفة لـ learning_rate\n",
    "    for lr in learning_rate_values:\n",
    "        gb = GradientBoostingClassifier(learning_rate=lr)\n",
    "        gb.fit(X_train, y_train)\n",
    "        y_pred = gb.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        gb_results.append({\n",
    "            'learning_rate': lr,\n",
    "            'accuracy': accuracy,\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "    return gb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "396d583a-9fe0-46ac-8e67-60fb43c6a343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'BMI', 'AlcoholConsumption', 'DietQuality', 'SleepQuality',\n",
      "       'SystolicBP', 'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL',\n",
      "       'CholesterolHDL', 'CholesterolTriglycerides', 'UPDRS', 'MoCA',\n",
      "       'FunctionalAssessment', 'WeeklyPhysicalActivity (hr)'],\n",
      "      dtype='object')\n",
      "      UPDRS  FunctionalAssessment      MoCA       Age  AlcoholConsumption  \\\n",
      "0  0.020778              0.535827  0.955136  0.358974            0.307946   \n",
      "1  0.885720              0.993524  0.677473  0.743590            0.259706   \n",
      "2  0.669861              0.570783  0.687600  0.897436            0.496248   \n",
      "3  0.783830              0.725532  0.140790  0.871795            0.944279   \n",
      "4  0.248810              0.612302  0.716372  0.230769            0.142690   \n",
      "5  0.415747              0.974350  0.847779  0.487179            0.377717   \n",
      "6  0.181951              0.876663  0.948996  0.102564            0.889189   \n",
      "7  0.604146              0.086266  0.229540  0.564103            0.786715   \n",
      "8  0.613343              0.934389  0.781175  0.871795            0.562684   \n",
      "9  0.610935              0.598157  0.886828  0.256410            0.715440   \n",
      "\n",
      "        BMI  DiastolicBP  CholesterolHDL  CholesterolTriglycerides  \\\n",
      "0  0.649610     0.525424        0.068965                  0.535004   \n",
      "1  0.718490     0.271186        0.038398                  0.285875   \n",
      "2  0.043377     0.372881        0.575932                  0.047898   \n",
      "3  0.965825     0.050847        0.271378                  0.566081   \n",
      "4  0.039184     0.694915        0.040323                  0.221900   \n",
      "5  0.307246     0.016949        0.647062                  0.108365   \n",
      "6  0.361341     0.338983        0.990263                  0.754507   \n",
      "7  0.702531     0.610169        0.278293                  0.777659   \n",
      "8  0.632364     0.288136        0.909093                  0.220242   \n",
      "9  0.118897     0.203390        0.879532                  0.883130   \n",
      "\n",
      "   CholesterolLDL  ... Rigidity Bradykinesia PosturalInstability Depression  \\\n",
      "0        0.215114  ...        0            0                   0          0   \n",
      "1        0.844191  ...        0            0                   0          1   \n",
      "2        0.989711  ...        0            0                   0          0   \n",
      "3        0.564134  ...        1            0                   0          0   \n",
      "4        0.063181  ...        0            0                   0          0   \n",
      "5        0.399022  ...        1            0                   0          0   \n",
      "6        0.198139  ...        0            0                   0          1   \n",
      "7        0.072404  ...        0            0                   1          0   \n",
      "8        0.410253  ...        1            0                   0          1   \n",
      "9        0.564998  ...        0            1                   0          0   \n",
      "\n",
      "  Diabetes Stroke Gender Constipation Hypertension Diagnosis  \n",
      "0        0      0      0            0            0         0  \n",
      "1        0      0      1            0            0         0  \n",
      "2        0      0      1            1            0         1  \n",
      "3        0      0      0            0            0         1  \n",
      "4        1      0      1            1            0         0  \n",
      "5        0      0      0            0            0         1  \n",
      "6        0      0      0            0            1         0  \n",
      "7        0      0      1            0            0         1  \n",
      "8        1      0      1            1            0         1  \n",
      "9        0      0      1            0            1         0  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "data=PreProcessing()\n",
    "print(data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ecb8de14-38f0-4c39-88b0-1381447733a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "C=0.1, Accuracy=0.7555555555555555\n",
      "Confusion Matrix:\n",
      "[[ 83  86]\n",
      " [ 13 223]]\n",
      "C=1, Accuracy=0.8345679012345679\n",
      "Confusion Matrix:\n",
      "[[126  43]\n",
      " [ 24 212]]\n",
      "C=10, Accuracy=0.8271604938271605\n",
      "Confusion Matrix:\n",
      "[[126  43]\n",
      " [ 27 209]]\n"
     ]
    }
   ],
   "source": [
    "svm_results=SVM(data)\n",
    "print(\"SVM Results:\")\n",
    "for result in svm_results:\n",
    "    print(f\"C={result['C']}, Accuracy={result['accuracy']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7ca898f-f31d-49b4-9f1d-06d8af274889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Results:\n",
      "learning_rate=0.01, Accuracy=0.782716049382716\n",
      "Confusion Matrix:\n",
      "[[ 94  75]\n",
      " [ 13 223]]\n",
      "learning_rate=0.1, Accuracy=0.9234567901234568\n",
      "Confusion Matrix:\n",
      "[[147  22]\n",
      " [  9 227]]\n",
      "learning_rate=0.3, Accuracy=0.9308641975308642\n",
      "Confusion Matrix:\n",
      "[[151  18]\n",
      " [ 10 226]]\n"
     ]
    }
   ],
   "source": [
    "gb_results=GB(data)\n",
    "print(\"\\nGradient Boosting Results:\")\n",
    "for result in gb_results:\n",
    "    print(f\"learning_rate={result['learning_rate']}, Accuracy={result['accuracy']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8fc1491-9459-438a-aa84-32273b597f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Results:\n",
      "max_depth=3, Accuracy=0.7876543209876543\n",
      "Confusion Matrix:\n",
      "[[ 97  72]\n",
      " [ 14 222]]\n",
      "max_depth=5, Accuracy=0.8765432098765432\n",
      "Confusion Matrix:\n",
      "[[151  18]\n",
      " [ 32 204]]\n",
      "max_depth=10, Accuracy=0.9135802469135802\n",
      "Confusion Matrix:\n",
      "[[149  20]\n",
      " [ 15 221]]\n"
     ]
    }
   ],
   "source": [
    "dt_results=DT(data)\n",
    "print(\"\\nDecision Tree Results:\")\n",
    "for result in dt_results:\n",
    "    print(f\"max_depth={result['max_depth']}, Accuracy={result['accuracy']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f77537-8d71-49c8-9fce-0323dd41760e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
